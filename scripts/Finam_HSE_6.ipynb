{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "1-oGoFip9QIk"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "candles = pd.read_csv('/content/candles.csv')\n",
        "candles_2 = pd.read_csv('/content/candles_2.csv')\n",
        "news = pd.read_csv('/content/news.csv')\n",
        "news_2 = pd.read_csv('/content/news_2.csv')"
      ],
      "metadata": {
        "id": "L7OIBXDVGorj"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pickle\n",
        "import csv\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# ====== Простая новостная фича: дневной news_count ======\n",
        "def add_news_count(candles: pd.DataFrame, news: pd.DataFrame | None) -> pd.DataFrame:\n",
        "    c = candles.copy()\n",
        "    c['begin'] = pd.to_datetime(c['begin'])\n",
        "    c['date'] = c['begin'].dt.normalize()\n",
        "    if news is None or len(news) == 0:\n",
        "        c['news_count'] = 0.0\n",
        "        return c.drop(columns=['date'])\n",
        "    n = news.copy()\n",
        "    n['publish_date'] = pd.to_datetime(n['publish_date'])\n",
        "    n['date'] = n['publish_date'].dt.normalize()\n",
        "    daily = n.groupby('date').size().reset_index(name='news_count')\n",
        "    out = c.merge(daily, on='date', how='left')\n",
        "    out['news_count'] = out['news_count'].fillna(0.0)\n",
        "    return out.drop(columns=['date'])\n",
        "\n",
        "# ====== Фичи и таргеты ======\n",
        "FEATS = ['momentum_5','volatility_5','price_range','news_count']\n",
        "\n",
        "def create_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    d = df.copy()\n",
        "    d['begin'] = pd.to_datetime(d['begin'])\n",
        "    d = d.sort_values(['ticker','begin']).reset_index(drop=True)\n",
        "    d['momentum_5'] = d.groupby('ticker')['close'].pct_change(5).fillna(0.0)\n",
        "    r1 = d.groupby('ticker')['close'].pct_change()\n",
        "    d['volatility_5'] = r1.groupby(d['ticker']).rolling(5, min_periods=1).std().reset_index(level=0, drop=True).fillna(0.0)\n",
        "    d['price_range'] = ((d['high'] - d['low'])/d['close']).fillna(0.0)\n",
        "    return d\n",
        "\n",
        "def create_targets(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    d = df.copy()\n",
        "    for h in (1,20):\n",
        "        d[f'target_return_{h}d'] = d.groupby('ticker')['close'].pct_change(h).shift(-h)\n",
        "    return d\n",
        "\n",
        "# ====== Обучение ======\n",
        "def fit(candles: pd.DataFrame, news: pd.DataFrame | None, model_path: str = 'model.pkl') -> None:\n",
        "    # Обучаем на всей истории, чтобы упростить воспроизведение на стороне организаторов [web:145]\n",
        "    df = create_features(candles)\n",
        "    df = add_news_count(df, news)\n",
        "    df = create_targets(df)\n",
        "    mask = ~df[['target_return_1d','target_return_20d']].isna().any(axis=1)\n",
        "    tr = df.loc[mask].reset_index(drop=True)\n",
        "    if len(tr) == 0:\n",
        "        raise ValueError(\"No training rows with valid targets for both horizons 1 and 20.\")\n",
        "    X = tr[FEATS].values\n",
        "    scaler = StandardScaler().fit(X)\n",
        "    Xs = scaler.transform(X)\n",
        "    models = {}\n",
        "    for h in (1,20):\n",
        "        y = tr[f'target_return_{h}d'].values\n",
        "        models[f'reg_{h}'] = LinearRegression().fit(Xs, y)\n",
        "    train_tickers = sorted(candles['ticker'].astype(str).unique().tolist())\n",
        "    with open(model_path, 'wb') as f:\n",
        "        pickle.dump({'features': FEATS, 'scaler': scaler, 'models': models, 'train_tickers': train_tickers}, f)\n",
        "\n",
        "# ====== Запись CSV ровно в формате примера (заголовок + 19 строк, значения без пробелов) ======\n",
        "def write_submission_csv(submission: pd.DataFrame, path: str) -> None:\n",
        "    header = ['ticker'] + [f'p{i}' for i in range(1, 21)]\n",
        "    sub = submission.copy()[header]\n",
        "    rows = []\n",
        "    for _, r in sub.iterrows():\n",
        "        row = [str(r['ticker'])]\n",
        "        for i in range(1, 21):\n",
        "            v = float(r[f'p{i}'])\n",
        "            row.append(f'{v:.6f}')\n",
        "        rows.append(row)\n",
        "    # Пишем CSV с запятой, CRLF, без BOM — строго предсказуемый текстовый формат [web:204][web:159]\n",
        "    with open(path, 'w', newline='', encoding='utf-8') as f:\n",
        "        w = csv.writer(f, delimiter=',', lineterminator='\\r\\n', quoting=csv.QUOTE_MINIMAL)\n",
        "        w.writerow(header)\n",
        "        w.writerows(rows)\n",
        "\n",
        "# ====== Предсказание: одна строка на тикер на выбранную дату (или на последнюю доступную) ======\n",
        "def predict_on_date(candles: pd.DataFrame,\n",
        "                    news: pd.DataFrame | None,\n",
        "                    model_path: str = 'model.pkl',\n",
        "                    output_path: str = 'submission.csv',\n",
        "                    cutoff_date: str | None = None) -> pd.DataFrame:\n",
        "    with open(model_path, 'rb') as f:\n",
        "        p = pickle.load(f)\n",
        "    feats, scaler, models, train_tickers = p['features'], p['scaler'], p['models'], p['train_tickers']\n",
        "\n",
        "    Xf = create_features(candles)\n",
        "    Xf = add_news_count(Xf, news)\n",
        "\n",
        "    # Если задана дата — берём максимальную begin ≤ cutoff_date по каждому тикеру; иначе — просто последний день [web:138]\n",
        "    if cutoff_date is not None:\n",
        "        cut = pd.to_datetime(cutoff_date)\n",
        "        Xf = Xf[Xf['begin'] <= cut].copy()\n",
        "        if len(Xf) == 0:\n",
        "            # Нет данных до даты — упадём на нулях, сохранив формат\n",
        "            pass\n",
        "    last_idx = Xf.groupby('ticker')['begin'].idxmax()\n",
        "    dfl = Xf.loc[last_idx].reset_index(drop=True)\n",
        "\n",
        "    # Гарантируем строки для всех тикеров из обучающего списка: если какого-то нет в dfl, заполним нулями [web:109]\n",
        "    dfl['ticker'] = dfl['ticker'].astype(str)\n",
        "    have = set(dfl['ticker'].tolist())\n",
        "    missing = [t for t in train_tickers if t not in have]\n",
        "    if len(missing):\n",
        "        # Добавим заглушки в dfl, чтобы итог был ровно по всем ожидаемым тикерам\n",
        "        pad = pd.DataFrame({'ticker': missing})\n",
        "        for col in feats + ['begin']:\n",
        "            pad[col] = np.nan\n",
        "        dfl = pd.concat([dfl, pad], ignore_index=True)\n",
        "\n",
        "    # Предикт\n",
        "    preds = []\n",
        "    for _, row in dfl.iterrows():\n",
        "        if pd.isna(row[feats]).any():\n",
        "            pr1 = 0.0\n",
        "            pr20 = 0.0\n",
        "        else:\n",
        "            Xrow = scaler.transform([row[feats].values])\n",
        "            pr1  = float(models['reg_1'].predict(Xrow)[0])\n",
        "            pr20 = float(models['reg_20'].predict(Xrow)[0])\n",
        "        alphas = np.linspace(0, 1, 20)\n",
        "        band = np.clip((1 - alphas) * pr1 + alphas * pr20, -0.5, 0.5)\n",
        "        rec = {'ticker': row['ticker']}\n",
        "        for i in range(20):\n",
        "            rec[f'p{i+1}'] = float(band[i])\n",
        "        preds.append(rec)\n",
        "\n",
        "    submission = pd.DataFrame(preds)\n",
        "    # Жёсткий порядок столбцов\n",
        "    submission = submission[['ticker'] + [f'p{i}' for i in range(1, 21)]]\n",
        "    # Жёсткая запись CSV как в примере\n",
        "    write_submission_csv(submission, output_path)\n",
        "    return submission\n",
        "\n",
        "# ====== Пример использования ======\n",
        "# 1) Обучение на history (candles.csv + news.csv)\n",
        "candles = pd.read_csv('/content/candles.csv')\n",
        "news = pd.read_csv('/content/news.csv')\n",
        "fit(candles, news)\n",
        "\n",
        "# 2A) Предсказание ровно на дату t (например, 2024-09-08) — 1 строка на тикер\n",
        "candles_2 = pd.read_csv('/content/candles_2.csv')\n",
        "news_2    = pd.read_csv('/content/news_2.csv')\n",
        "submission = predict_on_date(candles_2, news_2, model_path='model.pkl', output_path='submission.csv', cutoff_date='2024-09-08')\n",
        "\n",
        "# 2B) Или предсказание на последнюю доступную дату в candles_2 по каждому тикеру (если cutoff_date=None)\n",
        "submission = predict_on_date(candles_2, news_2, model_path='model.pkl', output_path='submission.csv', cutoff_date=None)\n"
      ],
      "metadata": {
        "id": "4IGbw0LnAhu5"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QqByXqjEtTWw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}